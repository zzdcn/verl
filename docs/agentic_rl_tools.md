# Agentic RL ä¸å·¥å…·å®ç°é€Ÿè§ˆ

æœ¬ç¬”è®°æ•´åˆ `docs/start/agentic_rl.rst`ã€`verl/tools/base_tool.py`ã€`verl/tools/gsm8k_tool.py`ã€`verl/tools/geo3k_tool.py`ã€`verl/tools/image_zoom_in_tool.py` ä»¥åŠ**å›¾ç‰‡ç†è§£ Agent + Resize å·¥å…·**éœ€æ±‚ï¼Œå¸®åŠ©å¿«é€Ÿæ­å»ºèƒ½å¤Ÿåˆ©ç”¨è§†è§‰å·¥å…·å®Œæˆ OCR ä»»åŠ¡çš„ Agentic RL æµç¨‹ã€‚

## 1. Agentic RL è®­ç»ƒè„‰ç»œ
 
- **å¼‚æ­¥ Rollout**ï¼šè®­ç»ƒç«¯ï¼ˆPPO Trainerï¼‰ä¸æ¨ç†ç«¯ï¼ˆAsyncServer, AsyncLLMServerManagerï¼‰è§£è€¦ï¼Œé€šè¿‡ Ray actor ç»´æŠ¤ç²˜æ€§ä¼šè¯ï¼Œé¿å…å·¥å…·è°ƒç”¨é˜»å¡ GPU (`docs/start/agentic_rl.rst`).
- **å¤šè½®å¯¹è¯ + å·¥å…·**ï¼šæ•°æ®é›†éœ€åŒ…å« `agent_name` å­—æ®µï¼ŒAgentLoop ä¾æ®è¯¥å­—æ®µé€‰æ‹© `single_turn_agent` æˆ– `tool_agent_loop`ï¼Œå¹¶åœ¨ rollout è¿‡ç¨‹ä¸­æ³¨å…¥å·¥å…· schema ä¸å·¥å…·å“åº”ã€‚
- **LangGraph / è‡ªå®šä¹‰ Agent**ï¼šAgentLoop å……å½“ LangGraph agent çš„é€‚é…å±‚ï¼Œä½¿ç”¨ç»Ÿä¸€çš„ token in/out æ¥å£ä¿è¯è®­ç»ƒä¸æ¨ç† token ä¸€è‡´ã€‚

ä¼ªä»£ç æ¦‚è§ˆï¼š

```python
async def run_agentic_rl_step(batch):
    mgr.wake_up_servers()
    outputs = []
    for chunk in batch.split(num_workers):
        agent_outputs = await worker.generate_sequences(chunk)
        outputs.append(agent_outputs)
    mgr.sleep_servers()
    return concat(outputs)
```

## 2. Tool Base Class (`verl/tools/base_tool.py`)

- `BaseTool` ç»Ÿä¸€äº†å·¥å…·ç”Ÿå‘½å‘¨æœŸï¼š`create â†’ execute â†’ calc_reward â†’ release`ï¼Œå¹¶è¦æ±‚æä¾› OpenAI Function æ ¼å¼çš„ `tool_schema`ã€‚
- æ‰§è¡Œé˜¶æ®µé€šè¿‡ `ToolResponse` è¿”å›æ–‡æœ¬/å›¾åƒ/è§†é¢‘ï¼Œå¤šæ¨¡å†…å®¹éœ€ä»¥åˆ—è¡¨å½¢å¼å­˜å‚¨ï¼Œä¾¿äº AgentLoop é‡ç»„æ¶ˆæ¯ã€‚

ä¼ªä»£ç ï¼š

```python
class BaseTool:
    def __init__(self, config, schema):
        self.tool_schema = schema or self.get_openai_tool_schema()

    async def create(self, instance_id=None, **kwargs):
        return instance_id or uuid4(), ToolResponse()

    async def execute(self, instance_id, parameters, **ctx):
        return ToolResponse(text="Updated"), 0.0, {}
```

## 3. æ•°å­¦å¥–åŠ±å·¥å…·

### 3.1 `Gsm8kTool` (`verl/tools/gsm8k_tool.py`)

- å¤„ç† `calc_gsm8k_reward` å·¥å…·è°ƒç”¨ï¼Œ`create` é˜¶æ®µç¼“å­˜åœ°é¢çœŸå€¼ç­”æ¡ˆï¼Œ`execute` å°†æ¨¡å‹è¾“å‡ºæ ‡å‡†åŒ–ä¸º `#### <answer>`ã€‚
- `calc_reward` é€šè¿‡ `verl.utils.reward_score.gsm8k.compute_score` èµ‹åˆ†ï¼Œè‹¥æ–°æäº¤æœªæé«˜å¥–åŠ±åˆ™ç»™äºˆ -0.05 æƒ©ç½šã€‚

ä¼ªä»£ç ï¼š

```python
async def execute(instance, params):
    normalized = ensure_hash_prefix(params["answer"])
    reward = await calc_reward(instance)
    delta = 0.0 if reward > cache[instance].reward else -0.05
    cache[instance].update(response=normalized, reward=reward)
    return ToolResponse(text=f"{normalized=}{reward=}"), delta, {}
```

### 3.2 `Geo3kTool` (`verl/tools/geo3k_tool.py`)

- ç»“æ„ä¸ GSM8K ç±»ä¼¼ï¼Œä½†å¥–åŠ±å‡½æ•°æ”¹ç”¨ `verl.utils.reward_score.geo3k.compute_score`ï¼Œä¸”ç­”æ¡ˆè¦æ±‚ä»¥ `\boxed{}` åŒ…è£¹ã€‚
- ä»éµå¾ªâ€œè‹¥å¥–åŠ±æœªæå‡åˆ™æƒ©ç½šâ€çš„ç­–ç•¥ï¼Œåˆ©äºæ¨¡å‹åæ€åå†æäº¤ã€‚

## 4. è§†è§‰è£å‰ªå·¥å…·ï¼š`ImageZoomInTool` (`verl/tools/image_zoom_in_tool.py`)

- æä¾›å›¾åƒå±€éƒ¨æ”¾å¤§åŠŸèƒ½ï¼Œæ”¯æŒ Ray è¿œç¨‹ worker + TokenBucket é™æµï¼Œé¿å…å¹¶å‘å›¾åƒè£å‰ªå¯¼è‡´çš„èµ„æºäº‰ç”¨ã€‚
- `create` é˜¶æ®µä¼šè§£ç å¤šç§å›¾åƒæ¥æºï¼ˆURLã€æœ¬åœ°ã€base64ï¼‰ï¼Œå¹¶ç¼“å­˜åŸå›¾ï¼›`execute` è¯»å– `bbox_2d`/`label`ï¼Œè‡ªåŠ¨æ ¡éªŒä¸æ‰©å±•è¿‡å°çš„æ¡†ï¼ˆæœ€å° 28x28ï¼‰ã€‚
- è‹¥è£å‰ªæˆåŠŸï¼Œè¿”å›æ–°çš„å›¾åƒåˆ‡ç‰‡ä¸æè¿°æ–‡æœ¬ï¼›å¦åˆ™è¿”å›é”™è¯¯æç¤ºå¹¶é™„ -0.05 æƒ©ç½šã€‚

ä¼ªä»£ç ï¼š

```python
async def execute(instance, params):
    bbox = sanitize_bbox(params["bbox_2d"], image.size)
    if not bbox:
        return ToolResponse(text="invalid bbox"), -0.05, {"success": False}
    cropped = image.crop(bbox)
    return ToolResponse(image=[cropped], text=f"Zoomed {bbox}"), 0.0, {"success": True}
```

## 5. å›¾ç‰‡ç†è§£ Agent + Resize å·¥å…·æ‰©å±•

ä¸ºäº†è®© OCR Agent å­¦ä¼šè‡ªé€‚åº”é€‰æ‹©â€œæ”¾å¤§/ç¼©å°â€å€æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªæ–°çš„ `ImageResizeTool`ï¼Œå¹¶åœ¨ AgentLoop é‡Œè¦æ±‚æ¨¡å‹å…ˆåˆ†æå½“å‰å›¾åƒï¼Œå†å†³å®šè¦è°ƒç”¨å·¥å…·ã€‚æ•´ä½“æ€è·¯å¦‚ä¸‹ï¼š

1. **å·¥å…·æ¥å£**ï¼šé™å®šè‹¥å¹²æ”¾å¤§/ç¼©å°å€æ•°ï¼ˆå¦‚ `[0.5, 1.0, 2.0, 4.0]`ï¼‰ï¼Œé€šè¿‡å‚æ•° `scale` æ§åˆ¶ `PIL.Image.resize`ï¼›è¿”å› `ToolResponse(image=[resized_img], text=...)` æ–¹ä¾¿æ¨¡å‹è¯»å–ã€‚å¯åœ¨å·¥å…·é…ç½®é‡Œå…è®¸è‡ªå®šä¹‰ `min_scale`/`max_scale`/`allowed_scales`ã€‚
2. **Agent ç­–ç•¥**ï¼š
   - å…ˆçœ‹åˆ°åŸå§‹é¢˜ç›®ï¼ˆå¯èƒ½é™„å¸¦ä½åˆ†è¾¨ç‡å›¾ï¼‰ï¼Œè§„åˆ’æ˜¯å¦éœ€è¦ resizeã€‚
   - ä¾æ®å·¥å…·è¿”å›çš„æ–°å›¾ç»§ç»­ OCR æ¨ç†ï¼Œæœ€ç»ˆäº§å‡ºæ–‡æœ¬ç­”æ¡ˆã€‚
3. **å¥–åŠ±è®¾è®¡**ï¼šç»“åˆ OCR æ­£ç¡®ç‡ï¼ˆå¦‚ CER/WER æˆ–é€šè¿‡æ ‡æ³¨ç­”æ¡ˆæ¯”å¯¹ï¼‰+ å·¥å…·è°ƒç”¨æˆæœ¬ï¼ˆä¾‹å¦‚è°ƒç”¨æ¬¡æ•°æƒ©ç½šï¼‰ï¼Œæ¿€åŠ±æ¨¡å‹â€œå¤Ÿç”¨å³æ­¢â€ã€‚

### 5.1 æ–°å·¥å…·å®ç°è‰æ¡ˆ

æ–‡ä»¶ï¼š`verl/tools/image_resize_tool.py`

```python
class ImageResizeTool(BaseTool):
    def __init__(self, config, tool_schema):
        super().__init__(config, tool_schema)
        self.allowed_scales = config.get("allowed_scales", [0.5, 1.0, 2.0, 4.0])
        self.interp = config.get("interpolation", "bicubic")

    async def create(self, instance_id=None, **kwargs):
        instance_id = instance_id or str(uuid4())
        img = fetch_image(kwargs.get("image") or kwargs["create_kwargs"]["image"])
        self._instances[instance_id] = {"image": img}
        return instance_id, ToolResponse()

    async def execute(self, instance_id, parameters, **kwargs):
        scale = float(parameters.get("scale", 1.0))
        if scale not in self.allowed_scales:
            return ToolResponse(text=f"scale {scale} not supported"), -0.05, {"success": False}
        img = self._instances[instance_id]["image"]
        size = (int(img.width * scale), int(img.height * scale))
        resized = img.resize(size, resample=getattr(Image, self.interp.upper()))
        text = f"Resized from {img.size} to {resized.size} (x{scale})."
        return ToolResponse(image=[resized], text=text), 0.0, {"success": True}
```

### 5.2 è®­ç»ƒé…ç½®ä¿®æ”¹

| æ­¥éª¤ | ä¿®æ”¹è¯´æ˜ |
| --- | --- |
| å·¥å…·é…ç½® | åœ¨ `examples/sglang_multiturn/config/tool_config/*.yaml` ä¸­æ–°å¢ `ImageResizeTool` æ¡ç›®ï¼ŒæŒ‡å®š `class_name`, `allowed_scales`, `tool_schema`ï¼ˆåŒ…å« `scale` å‚æ•°ï¼Œå€¼åŸŸå¯é€‰åˆ—è¡¨ï¼‰ã€‚ |
| æ•°æ®å‡†å¤‡ | æ•°æ®é›†ä¸­è¿½åŠ  `agent_name="tool_agent"`ã€`tools_kwargs.image_resize_tool.create_kwargs.image=<åŸå›¾>`ï¼Œå¹¶åœ¨ `prompt` ä¸­æç¤ºâ€œå¯è°ƒç”¨ resize å·¥å…·ä»¥ååŠ© OCRâ€ã€‚ |
| Rollout | `actor_rollout_ref.rollout.multi_turn.tool_config_path` æŒ‡å‘åŒ…å«æ–°å·¥å…·çš„ YAMLï¼›å¿…è¦æ—¶åœ¨ `tool_agent_loop` ä¸­å°†å·¥å…·è¿”å›çš„å¤šæ¨¡å†…å®¹å†™å…¥æ¶ˆæ¯ï¼ˆImageZoomIn å·²æ”¯æŒå›¾åƒåˆ—è¡¨ï¼‰ã€‚ |
| å¥–åŠ± | å¯å¤ç”¨ `verl.utils.reward_score` çš„è‡ªå®šä¹‰å‡½æ•°æˆ–ç¼–å†™æ–° reward loopï¼Œæ¯”è¾ƒ OCR è¾“å‡ºä¸çœŸå€¼ï¼›å¦å¯åœ¨ `AgentLoopOutput.extra_fields` é‡Œç»Ÿè®¡ tool è°ƒç”¨æ¬¡æ•°ä¾›å¤–éƒ¨å¥–åŠ±é€»è¾‘å‚è€ƒã€‚ |
| æ¨ç†/Serving | æ¨ç†é˜¶æ®µéœ€éƒ¨ç½²ç›¸åŒå·¥å…·ï¼Œç¡®ä¿è®­ç»ƒ/ä¸Šçº¿ä¸€è‡´æ€§ã€‚ |

### 5.3 Agent å›åˆç¤ºä¾‹ï¼ˆä¼ªå¯¹è¯ï¼‰

```text
user  : è¿™æ˜¯æ‰«ææ–‡æ¡£çš„ä¸€éƒ¨åˆ†ï¼Œè¯·æŠ„å½•æ–‡å­—ã€‚ä½ å¯ä»¥è°ƒç”¨ image_resize_tool æ”¾å¤§æˆ–ç¼©å°ã€‚
assistant(thinking): å›¾åƒæ¨¡ç³Šï¼Œå†³å®šå…ˆæ”¾å¤§ 2 å€ã€‚
assistant(tool_call): image_resize_tool({"scale": 2.0})
tool  : è¿”å›æ”¾å¤§å›¾ç‰‡ + æè¿°
assistant(thinking): è¯»å–æ¸…æ™°åŒºåŸŸï¼Œè¾“å‡º OCR ç»“æœã€‚
assistant(final): <æ–‡å­—ç­”æ¡ˆ>
```

## 6. æ•°æ®é›†æ„å»ºæŒ‡å—

Agentic RL æ•°æ®é›†éœ€è¦åŒæ—¶æºå¸¦æ–‡æœ¬æç¤ºã€åŸå§‹å›¾åƒå¼•ç”¨ã€å·¥å…·ä¸Šä¸‹æ–‡ä»¥åŠå¥–åŠ±ç›¸å…³å…ƒä¿¡æ¯ã€‚å»ºè®®æµç¨‹ï¼š

1. **æ”¶é›†åŸå§‹æ ·æœ¬**ï¼šåŒ…å«å›¾åƒè·¯å¾„/URLä¸ OCR ç›®æ ‡æ–‡æœ¬ã€‚
2. **é¢„å¤„ç†è„šæœ¬**ï¼šä»¿ç…§ `examples/data_preprocess/gsm8k_tool_agent_loop.py` å†™ `ocr_resize_agent_loop.py`ï¼Œæ ¸å¿ƒæ­¥éª¤ï¼š

```python
sample = {
    "agent_name": "tool_agent",
    "prompt": [
        {"role": "system", "content": "ä½ æ˜¯OCRåŠ©æ‰‹ï¼Œå¯è°ƒç”¨image_resize_toolã€‚"},
        {"role": "user", "content": "è¯·æŠ„å½•é™„ä»¶ä¸­çš„æ–‡å­—ã€‚"}
    ],
    "extra_info": {
        "answer": target_text,
        "image_path": image_uri,
        "split": split,
    },
    "tools_kwargs": {
        "image_resize_tool": {
            "create_kwargs": {"image": image_uri}
        }
    },
    "reward_model": {
        "style": "ocr_rule",
        "ground_truth": target_text,
    }
}
```

3. **è¾“å‡ºæ ¼å¼**ï¼šæ¨èå†™å…¥ parquet (`dataset.to_parquet(...)`) æˆ– HuggingFace JSONLï¼Œç¡®ä¿ `return_raw_chat=True` æ—¶ `RLHFDataset` èƒ½ç›´æ¥è¯»å– `prompt` åˆ—è¡¨ã€‚
4. **å­—æ®µçº¦å®š**ï¼š
   - `agent_name`ï¼šå†³å®šæ˜¯å¦å¯ç”¨ `ToolAgentLoop`ã€‚
   - `tools_kwargs`ï¼šä¸ºå·¥å…·çš„ `create/execute` ä¼ å‚ï¼ŒåŒ…å«å›¾åƒã€ground truth ç­‰ã€‚
   - `extra_info.interaction_kwargs`ï¼šè‹¥éœ€å¼•å…¥æ¨¡æ‹Ÿç”¨æˆ·å¯åœ¨æ­¤é…ç½®ã€‚
   - `reward_model`ï¼šå£°æ˜å¥–åŠ±é£æ ¼ï¼ˆrule-based / model-basedï¼‰ï¼Œä»¥ä¾¿ RewardLoop è§£æã€‚

## 7. å¥–åŠ±å®ç°ä¸é›†æˆ

### 7.1 è§„åˆ™å¥–åŠ±ï¼ˆOCR ç¤ºä¾‹ï¼‰

å¯åœ¨ `verl/utils/reward_score` ä¸‹æ–°å¢ `ocr.py`ï¼Œæä¾› `compute_score(pred, label, metric="cer")`ã€‚å¥–åŠ±é€»è¾‘ï¼š

```python
def compute_score(pred, label, metric="cer"):
    pred_norm = normalize(pred)
    label_norm = normalize(label)
    cer = levenshtein(pred_norm, label_norm) / max(1, len(label_norm))
    return max(0.0, 1.0 - cer)
```

å·¥å…·è°ƒç”¨å›åˆç»“æŸåï¼Œ`AgentLoopOutput.extra_fields` ä¼šé™„å¸¦ `reward_model` ä¿¡æ¯ï¼›RewardLoop (`verl.experimental.reward_loop`) è¯»å– batch å¹¶è°ƒç”¨ä¸Šè¿°å‡½æ•°å¾—åˆ°æ ‡é‡å¥–åŠ±ï¼Œå¯å†å åŠ ï¼š

- å·¥å…·è°ƒç”¨æ•°æƒ©ç½šï¼š`reward -= 0.01 * num_tool_calls`
- æœªä½¿ç”¨å·¥å…·ä½† CER > é˜ˆå€¼æ—¶é™„åŠ è´Ÿå¥–åŠ±ã€‚

### 7.2 æ¨¡å‹å¥–åŠ±

è‹¥éœ€å¼•å…¥å¤šæ¨¡ RMï¼Œå¯åœ¨ `reward_model` é…ç½®ä¸­å¼€å¯ `use_reward_loop=True` å¹¶æä¾›è‡ªå®šä¹‰ `RewardModelWorker`ï¼›æ•°æ®å‡†å¤‡é˜¶æ®µæŠŠå›¾åƒ/æ–‡æœ¬ä¸€å¹¶å¡å…¥ `non_tensor_batch["multi_modal_inputs"]`ï¼Œä¿è¯ RM èƒ½å¤ç°ä¸Šä¸‹æ–‡ã€‚

### 7.3 è®­ç»ƒè„šæœ¬å¯¹æ¥

- åœ¨ Hydra é…ç½®é‡Œè®¾ç½® `reward_model.style: ocr_rule` å¹¶æŒ‡å‘å®ç°è„šæœ¬ã€‚
- `ppo_trainer` ä¼šåœ¨ rollout åè°ƒç”¨ RewardLoopï¼›è‹¥ reward å·²åœ¨ AgentLoop å†…ç›´æ¥è®¡ç®—ï¼ˆä¾‹å¦‚å·¥å…·å³æ—¶è¯„åˆ†ï¼‰ï¼Œå¯é€šè¿‡ `AgentLoopOutput.reward_score` è¿”å›ï¼Œè·³è¿‡ RMã€‚

## 8. å®Œæ•´è®­ç»ƒæµç¨‹ Checklist

1. **å‡†å¤‡å·¥å…·**ï¼š
   - åœ¨ `examples/sglang_multiturn/config/tool_config/ocr_resize.yaml` ä¸­ç™»è®° `ImageResizeTool`ã€`ImageZoomInTool` ç­‰ã€‚
   - è‹¥æœ‰å¤šæ¨¡å·¥å…·ï¼Œç¡®ä¿æ¨¡å‹ processor æ”¯æŒã€‚
2. **æ„å»ºæ•°æ®**ï¼šè¿è¡Œè‡ªå®šä¹‰ preprocess è„šæœ¬ç”Ÿæˆ parquetï¼Œå­—æ®µåŒ…å« `prompt/agent_name/tools_kwargs/reward_model`ã€‚
3. **é…ç½® Rollout**ï¼š
   - `actor_rollout_ref.rollout.multi_turn.enable=True`
   - `...tool_config_path=.../ocr_resize.yaml`
   - æŒ‰éœ€è®¾ç½® `max_assistant_turns`, `max_parallel_calls`ã€‚
4. **å¥–åŠ±é›†æˆ**ï¼šåœ¨ `reward_model` é…ç½®é‡Œé€‰æ‹© `use_reward_loop` æˆ– `rule`ï¼Œç¡®ä¿è„šæœ¬å¯è¢«å¯¼å…¥ã€‚
5. **å¯åŠ¨è®­ç»ƒ**ï¼šä¾‹å¦‚

```bash
bash examples/sglang_multiturn/run_qwen2.5-3b_gsm8k_tool_agent_mlflow.sh \
  data.train_path=~/data/ocr/train.parquet \
  actor_rollout_ref.rollout.multi_turn.tool_config_path=.../ocr_resize.yaml \
  trainer.project_name=ocr_agentic_rl
```

6. **ç›‘æ§ä¸è°ƒè¯•**ï¼š
   - `mlflow ui` æˆ– `rollout trace` æ£€æŸ¥å·¥å…·è°ƒç”¨/tokenizationã€‚
   - æ ¹æ®æ—¥å¿—ä¸­ `agent_loop/tool_calls`ã€`reward_value` è°ƒæ•´å¥–åŠ±æƒé‡ã€‚
7. **éªŒæ”¶**ï¼šä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„å·¥å…·é…ç½®åœ¨ validation é›†ä¸Š rolloutï¼Œè¯„ä¼° CER/WER ä¸å¹³å‡è°ƒç”¨æ¬¡æ•°ï¼›å¿…è¦æ—¶è’¸é¦æˆæ— å·¥å…·æ¨¡å‹ä¾›æ¨ç†ã€‚

## 9. ç»“åˆ AgentLoop çš„ä½¿ç”¨å»ºè®®

1. **é…ç½®å·¥å…·**ï¼šåœ¨ rollout é…ç½®é‡Œè®¾ç½® `actor_rollout_ref.rollout.multi_turn.tool_config_path`ï¼ŒæŒ‡å‘åŒ…å«ä¸Šè¿°å·¥å…· schema çš„ YAMLã€‚
2. **å‡†å¤‡æ•°æ®**ï¼šæ•°æ®æ ·æœ¬è¦åŒ…å« `agent_name="tool_agent"`ã€`tools_kwargs`ï¼ˆå¦‚ä¸º GSM8K/Geo3K ä¼  ground truthï¼‰ç­‰å­—æ®µï¼ŒAgentLoop ä¼šè‡ªåŠ¨é€ä¼ ã€‚
3. **ç›‘æ§å¼‚æ­¥æ‰§è¡Œ**ï¼šåˆ©ç”¨ AgentLoop trace/mlflowï¼ˆè§ `docs/start/agentic_rl.rst`ï¼‰è§‚å¯Ÿå·¥å…·è°ƒç”¨æƒ…å†µï¼Œæ ¸å¯¹ tokenization ä¸€è‡´æ€§ï¼Œå¹¶ç»Ÿè®¡ resize å·¥å…·ä½¿ç”¨é¢‘æ¬¡/æˆåŠŸç‡ä»¥è¯„ä¼°ç­–ç•¥ã€‚

è¯¥æ–‡æ¡£å¯ä½œä¸ºå¼€å‘ Agentic RL + å·¥å…·è°ƒç”¨ä»»åŠ¡çš„é€ŸæŸ¥è¡¨ï¼Œæ ¹æ®éœ€è¦æ‰©å±•æ–°çš„ Tool ç±»æˆ– LangGraph Agentã€‚

---

## 10. OCR Resize Agent è®­ç»ƒå®ç°è®¡åˆ’

æœ¬èŠ‚åŸºäº `eval_ocr/` é¡¹ç›®ä¸­å·²å®ç°çš„è¯„ä¼°é€»è¾‘ï¼Œåˆ¶å®šå®Œæ•´çš„ RL è®­ç»ƒå®ç°è®¡åˆ’ã€‚

### 10.1 é¡¹ç›®èƒŒæ™¯

`eval_ocr/` é¡¹ç›®å®ç°äº†ä¸€ä¸ªå¤šå¡å¹¶è¡Œçš„ OCR æ¨¡å‹è¯„ä¼°è„šæœ¬ï¼Œæ ¸å¿ƒç‰¹æ€§ï¼š

- **Batch å†… Agent å¹¶è¡Œæ¨ç†**ï¼šä½¿ç”¨åŠ¨æ€ Batch ç®¡ç†ï¼Œå¤„ç†ä¸åŒæ ·æœ¬å¼‚æ­¥å®Œæˆçš„æƒ…å†µ
- **å·¥å…·è°ƒç”¨**ï¼š`resize` å·¥å…·æ”¯æŒå›¾åƒæ”¾å¤§/ç¼©å°
- **å¤šç±»å‹æŒ‡æ ‡**ï¼šæ”¯æŒ textï¼ˆç¼–è¾‘è·ç¦»ï¼‰ã€tableï¼ˆTEDSï¼‰ã€formulaï¼ˆCDMï¼‰ä¸‰ç§è¯„ä¼°
- **å¤šå¡åˆ†å¸ƒå¼**ï¼šåŸºäº Accelerate å®ç°

### 10.2 è¯„ä¼°ä¸è®­ç»ƒçš„å¯¹åº”å…³ç³»

| eval_ocr ç»„ä»¶ | verl è®­ç»ƒå¯¹åº”ç»„ä»¶ | è¯´æ˜ |
|--------------|------------------|------|
| `BatchAgentRunner` | `ToolAgentLoop` | Agent æ¨ç†å¾ªç¯ |
| `AgentState` dataclass | `AgentData` class | æ ·æœ¬çŠ¶æ€ç®¡ç† |
| `parse_tool_call()` | `ToolParser` (hermes/gpt-oss) | å·¥å…·è°ƒç”¨è§£æ |
| `resize_image()` | `ImageResizeTool.execute()` | å·¥å…·æ‰§è¡Œ |
| `compute_metrics()` | `RewardLoop` / rule-based reward | å¥–åŠ±è®¡ç®— |
| Accelerate å¤šå¡ | Ray + FSDP/Megatron | åˆ†å¸ƒå¼è®­ç»ƒ |

### 10.3 è®­ç»ƒå®ç°è®¡åˆ’

#### Phase 1: å·¥å…·å®ç° (`verl/tools/image_resize_tool.py`)

**ç›®æ ‡**ï¼šå®ç°ä¸ eval_ocr é€»è¾‘ä¸€è‡´çš„ resize å·¥å…·

```python
# verl/tools/image_resize_tool.py
from uuid import uuid4
from PIL import Image
from qwen_vl_utils import fetch_image

from verl.tools.base_tool import BaseTool
from verl.tools.schemas import OpenAIFunctionToolSchema, ToolResponse

class ImageResizeTool(BaseTool):
    """å›¾åƒç¼©æ”¾å·¥å…·ï¼Œæ”¯æŒæ”¾å¤§/ç¼©å°ä»¥ä¼˜åŒ– OCR è¯†åˆ«æ•ˆæœ"""

    def __init__(self, config: dict, tool_schema: OpenAIFunctionToolSchema):
        super().__init__(config, tool_schema)
        self._instances = {}
        # é…ç½®é¡¹ï¼ˆä¸ eval_ocr ä¸€è‡´ï¼‰
        self.allowed_scales = config.get("allowed_scales", [0.5, 1.0, 2.0, 4.0])
        self.interpolation = config.get("interpolation", "LANCZOS")
        self.step_reward = config.get("step_reward", 0.0)  # æ¯æ¬¡è°ƒç”¨çš„å³æ—¶å¥–åŠ±
        self.invalid_scale_penalty = config.get("invalid_scale_penalty", -0.05)

    async def create(self, instance_id=None, **kwargs):
        """åˆå§‹åŒ–å·¥å…·å®ä¾‹ï¼Œç¼“å­˜åŸå§‹å›¾åƒ"""
        instance_id = instance_id or str(uuid4())
        create_kwargs = kwargs.get("create_kwargs", {})
        if create_kwargs:
            kwargs.update(create_kwargs)

        image = kwargs.get("image")
        if image is None:
            raise ValueError("Missing required 'image' parameter")

        # æ”¯æŒå¤šç§å›¾åƒæ¥æºï¼ˆURLã€æœ¬åœ°è·¯å¾„ã€base64ï¼‰
        img = fetch_image({"image": image})
        self._instances[instance_id] = {
            "original_image": img,
            "current_image": img,
            "resize_count": 0,
        }
        return instance_id, ToolResponse()

    async def execute(self, instance_id, parameters, **kwargs):
        """æ‰§è¡Œå›¾åƒç¼©æ”¾"""
        scale = parameters.get("scale")

        # éªŒè¯ scale å‚æ•°
        if scale is None:
            return (
                ToolResponse(text="Error: 'scale' parameter is required."),
                self.invalid_scale_penalty,
                {"success": False}
            )

        try:
            scale = float(scale)
        except (ValueError, TypeError):
            return (
                ToolResponse(text=f"Error: 'scale' must be a number, got {type(scale).__name__}."),
                self.invalid_scale_penalty,
                {"success": False}
            )

        if scale not in self.allowed_scales:
            return (
                ToolResponse(text=f"Error: scale {scale} not supported. Allowed: {self.allowed_scales}"),
                self.invalid_scale_penalty,
                {"success": False}
            )

        instance_data = self._instances.get(instance_id)
        if not instance_data:
            return (
                ToolResponse(text="Error: Invalid instance_id."),
                self.invalid_scale_penalty,
                {"success": False}
            )

        # æ‰§è¡Œç¼©æ”¾ï¼ˆä¸ eval_ocr ä¸€è‡´ï¼‰
        current_image = instance_data["current_image"]
        new_size = (int(current_image.width * scale), int(current_image.height * scale))
        resample = getattr(Image.Resampling, self.interpolation, Image.Resampling.LANCZOS)
        resized_image = current_image.resize(new_size, resample)

        # æ›´æ–°çŠ¶æ€
        instance_data["current_image"] = resized_image
        instance_data["resize_count"] += 1

        # ç”Ÿæˆåé¦ˆæ–‡æœ¬ï¼ˆä¸ eval_ocr SFT æ ¼å¼ä¸€è‡´ï¼‰
        if scale < 1.0:
            feedback = f"Downsampling complete. Scale: {scale}x."
        else:
            feedback = f"Upsampling complete. Scale: {scale}x."
        feedback += f"\nImage resized from {current_image.size} to {resized_image.size}."

        return (
            ToolResponse(image=[resized_image], text=feedback),
            self.step_reward,
            {"success": True, "scale": scale, "new_size": resized_image.size}
        )

    async def release(self, instance_id, **kwargs):
        """é‡Šæ”¾å·¥å…·å®ä¾‹"""
        if instance_id in self._instances:
            del self._instances[instance_id]
```

**å·¥å…·é…ç½® YAML** (`examples/sglang_multiturn/config/tool_config/ocr_resize_tool_config.yaml`):

```yaml
tools:
  - class_name: "verl.tools.image_resize_tool.ImageResizeTool"
    config:
      # ä¸ SFT è®­ç»ƒæ•°æ®ä¸€è‡´çš„ scale å€¼
      allowed_scales: [0.125, 0.143, 0.167, 0.2, 0.25, 0.333, 0.5, 2, 3, 4, 5, 6, 7, 8]
      interpolation: "LANCZOS"
      step_reward: 0.0
      invalid_scale_penalty: -0.05
    tool_schema:
      type: "function"
      function:
        name: "resize"
        description: |
          Resize the current image by a scale factor to optimize OCR recognition.
          Allowed scale values: 0.125, 0.143, 0.167, 0.2, 0.25, 0.333, 0.5, 2, 3, 4, 5, 6, 7, 8
          - scale < 1: Decrease resolution. For example: scale=0.5 means half size
          - scale > 1: Increase resolution. For example: scale=2 means 2x larger
        parameters:
          type: "object"
          properties:
            scale:
              type: "number"
              description: "Scale factor for resizing."
          required: ["scale"]
```

#### Phase 2: æ•°æ®é¢„å¤„ç†è„šæœ¬ (`examples/data_preprocess/ocr_resize_agent_loop.py`)

**ç›®æ ‡**ï¼šå°† OCR æ•°æ®é›†è½¬æ¢ä¸º verl è®­ç»ƒæ ¼å¼ï¼Œ**ä¸ SFT è®­ç»ƒæ•°æ®ä¿æŒæ ¼å¼ä¸€è‡´**

```python
# examples/data_preprocess/ocr_resize_agent_loop.py
"""
å°† OCR æ•°æ®é›†é¢„å¤„ç†ä¸º verl Agentic RL è®­ç»ƒæ ¼å¼
ä¸ SFT è®­ç»ƒæ•°æ®æ ¼å¼å®Œå…¨ä¸€è‡´ï¼Œç¡®ä¿è®­æ¨ä¸€è‡´æ€§

è¾“å…¥æ ¼å¼ (JSON/JSONL):
{
    "img_path_sh": "/path/to/image.jpg",
    "groundtruth": "è¯†åˆ«ç»“æœæ–‡æœ¬",
    "data_id": "text_block_000001",  # å¯é€‰ï¼Œç”¨äºæ¨æ–­ tag
    "tag": "text"  # å¯é€‰ï¼Œtext/table/equation
}

è¾“å‡ºæ ¼å¼ (Parquet):
{
    "data_source": "ocr_dataset",
    "agent_name": "tool_agent",
    "prompt": [...],
    "extra_info": {...},
    "reward_model": {...}
}
"""

import argparse
import json
import os
from pathlib import Path

import datasets

# ============================================================================
# ç³»ç»Ÿæç¤º - æŒ‰ tag ç±»å‹åˆ†ç±»ï¼ˆä¸ SFT è®­ç»ƒæ•°æ®å®Œå…¨ä¸€è‡´ï¼‰
# ============================================================================

# é€šç”¨å·¥å…·è¯´æ˜
TOOL_INSTRUCTION = """
You have access to a resize tool that can adjust the image resolution:
<tool_call>{"name": "resize", "arguments": {"scale": N}}</tool_call>
where N can be: 0.125, 0.143, 0.167, 0.2, 0.25, 0.333, 0.5, 2, 3, 4, 5, 6, 7, 8
- scale < 1: Decrease resolution. For example: scale=0.5 means half size
- scale > 1: Increase resolution. For example: scale=2 means 2x larger

When you complete the extraction, wrap your result with <final_answer> tags.
"""

SYSTEM_PROMPTS = {
    "text": (
        "You are an expert OCR assistant. Your task is to accurately extract all text content from the given image.\n"
        + TOOL_INSTRUCTION
        + "\nOutput format:\n- Output text in reading order\n- Preserve paragraph structure"
    ),
    "table": (
        "You are an expert OCR assistant. Your task is to accurately extract the table content from the given image and output it in HTML format.\n"
        + TOOL_INSTRUCTION
        + "\nOutput format:\n- Use <table border=\"1\"> as the opening tag\n- Use <tr> for rows, <td> for cells"
    ),
    "equation": (
        "You are an expert OCR assistant. Your task is to accurately extract the mathematical equation from the given image and output it in LaTeX format.\n"
        + TOOL_INSTRUCTION
        + "\nOutput format:\n- Output the equation in LaTeX format\n- Use standard LaTeX math notation"
    ),
}

USER_PROMPTS = {
    "text": "Extract all text content from this image.",
    "table": "Extract the table content from this image in HTML format.",
    "equation": "Extract the mathematical equation from this image in LaTeX format.",
}


def infer_tag(data_id: str) -> str:
    """æ ¹æ® data_id æ¨æ–­æ•°æ®ç±»å‹"""
    if data_id:
        data_id_lower = data_id.lower()
        if "equation" in data_id_lower or "formula" in data_id_lower:
            return "equation"
        elif "table" in data_id_lower:
            return "table"
    return "text"


def load_raw_dataset(data_path: str) -> list:
    """åŠ è½½åŸå§‹ JSON/JSONL æ•°æ®é›†"""
    data = []
    path = Path(data_path)

    if path.suffix == ".jsonl":
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
    elif path.suffix == ".json":
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, dict):
                data = [data]
    else:
        raise ValueError(f"Unsupported file format: {path.suffix}")

    return data


def process_sample(example: dict, idx: int, split: str) -> dict:
    """å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œè½¬æ¢ä¸º verl è®­ç»ƒæ ¼å¼"""
    # å­—æ®µæ˜ å°„
    image_path = example.get("img_path_sh") or example.get("image")
    ground_truth = example.get("groundtruth") or example.get("ground_truth")
    data_id = example.get("data_id", f"{split}_{idx:06d}")
    tag = example.get("tag") or infer_tag(data_id)

    if not image_path or not ground_truth:
        raise ValueError(f"Missing required fields in sample {idx}")

    # è·å– tag å¯¹åº”çš„ promptï¼ˆä¸ SFT æ•°æ®ä¸€è‡´ï¼‰
    system_prompt = SYSTEM_PROMPTS.get(tag, SYSTEM_PROMPTS["text"])
    user_prompt = USER_PROMPTS.get(tag, USER_PROMPTS["text"])

    # æ„å»º verl è®­ç»ƒæ ¼å¼
    # æ³¨æ„ï¼šä½¿ç”¨ "<image>" å ä½ç¬¦æ ¼å¼ï¼Œä¸ SFT æ•°æ®ä¸€è‡´
    return {
        "data_source": "ocr_dataset",
        "agent_name": "tool_agent",  # å¯ç”¨ ToolAgentLoop
        "prompt": [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": f"<image>{user_prompt}"  # ä¸ SFT æ ¼å¼ä¸€è‡´
            }
        ],
        "ability": "ocr",
        "reward_model": {
            "style": "rule",
            "ground_truth": ground_truth,
            "tag": tag,
        },
        "extra_info": {
            "split": split,
            "index": idx,
            "data_id": data_id,
            "tag": tag,
            "ground_truth": ground_truth,
            "image_path": image_path,
            "need_tools_kwargs": True,
            "tools_kwargs": {
                "resize": {
                    "create_kwargs": {"image": image_path}
                }
            },
        },
    }


def main():
    parser = argparse.ArgumentParser(description="Preprocess OCR dataset for verl training")
    parser.add_argument("--input_path", type=str, required=True, help="Input JSON/JSONL file")
    parser.add_argument("--output_dir", type=str, default="~/data/ocr_verl", help="Output directory")
    parser.add_argument("--train_ratio", type=float, default=0.9, help="Train split ratio")
    args = parser.parse_args()

    # åŠ è½½æ•°æ®
    raw_data = load_raw_dataset(args.input_path)
    print(f"Loaded {len(raw_data)} samples from {args.input_path}")

    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    split_idx = int(len(raw_data) * args.train_ratio)
    train_data = raw_data[:split_idx]
    test_data = raw_data[split_idx:]

    # å¤„ç†æ•°æ®
    train_processed = [process_sample(ex, i, "train") for i, ex in enumerate(train_data)]
    test_processed = [process_sample(ex, i, "test") for i, ex in enumerate(test_data)]

    # è½¬æ¢ä¸º HuggingFace Dataset
    train_dataset = datasets.Dataset.from_list(train_processed)
    test_dataset = datasets.Dataset.from_list(test_processed)

    # ä¿å­˜
    output_dir = os.path.expanduser(args.output_dir)
    os.makedirs(output_dir, exist_ok=True)

    train_dataset.to_parquet(os.path.join(output_dir, "train.parquet"))
    test_dataset.to_parquet(os.path.join(output_dir, "test.parquet"))

    print(f"Saved {len(train_processed)} train samples to {output_dir}/train.parquet")
    print(f"Saved {len(test_processed)} test samples to {output_dir}/test.parquet")


if __name__ == "__main__":
    main()
```

#### Phase 3: å¥–åŠ±å‡½æ•°å®ç° (`verl/utils/reward_score/ocr.py`)

**ç›®æ ‡**ï¼šå®ç°ä¸ eval_ocr ä¸€è‡´çš„æŒ‡æ ‡è®¡ç®—é€»è¾‘

```python
# verl/utils/reward_score/ocr.py
"""
OCR ä»»åŠ¡å¥–åŠ±å‡½æ•°ï¼Œæ”¯æŒä¸‰ç§æ•°æ®ç±»å‹ï¼š
- text: ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦
- table: TEDS åˆ†æ•°
- formula: CDM (Character Detection Matching) åˆ†æ•°
"""

import re
from typing import Dict, Any

import editdistance


def normalize_text(text: str) -> str:
    """æ–‡æœ¬æ ‡å‡†åŒ–"""
    if not text:
        return ""
    # å»é™¤å¤šä½™ç©ºç™½
    text = re.sub(r'\s+', ' ', text.strip())
    return text


def compute_edit_distance_similarity(pred: str, gt: str) -> float:
    """
    è®¡ç®—ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦ (å½’ä¸€åŒ–åˆ° [0, 1])

    Args:
        pred: é¢„æµ‹æ–‡æœ¬
        gt: çœŸå®æ–‡æœ¬

    Returns:
        float: ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œ1.0 ä¸ºå®Œå…¨åŒ¹é…
    """
    pred_norm = normalize_text(pred)
    gt_norm = normalize_text(gt)

    if not gt_norm:
        return 1.0 if not pred_norm else 0.0

    distance = editdistance.eval(pred_norm, gt_norm)
    max_len = max(len(pred_norm), len(gt_norm))

    if max_len == 0:
        return 1.0

    similarity = 1.0 - (distance / max_len)
    return max(0.0, similarity)


def compute_teds_score(pred: str, gt: str) -> Dict[str, float]:
    """
    è®¡ç®— TEDS (Tree-Edit-Distance-based Similarity) åˆ†æ•°

    éœ€è¦å®‰è£…: pip install table_recognition_metric
    """
    try:
        from table_recognition_metric import TEDS
        teds = TEDS(structure_only=False)
        teds_struct = TEDS(structure_only=True)

        score = teds.evaluate(pred, gt)
        score_struct = teds_struct.evaluate(pred, gt)

        return {
            "teds": score,
            "teds_struct": score_struct,
        }
    except ImportError:
        # Fallback to edit distance if TEDS not available
        similarity = compute_edit_distance_similarity(pred, gt)
        return {
            "teds": similarity,
            "teds_struct": similarity,
        }
    except Exception:
        return {"teds": 0.0, "teds_struct": 0.0}


def compute_formula_similarity(pred: str, gt: str) -> Dict[str, float]:
    """
    è®¡ç®—å…¬å¼ç›¸ä¼¼åº¦ (CDM)

    CDM éœ€è¦é¢å¤–çš„ç³»ç»Ÿä¾èµ–ï¼ˆLaTeX æ¸²æŸ“ï¼‰ï¼Œè¿™é‡Œæä¾›ç®€åŒ–ç‰ˆæœ¬
    """
    # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨ç¼–è¾‘è·ç¦»
    # TODO: é›†æˆå®Œæ•´çš„ CDM å®ç°
    similarity = compute_edit_distance_similarity(pred, gt)
    return {
        "recall": similarity,
        "precision": similarity,
        "f1_score": similarity,
    }


def compute_score(
    pred: str,
    gt: str,
    tag: str = "text",
    tool_call_count: int = 0,
    tool_penalty: float = 0.01,
) -> float:
    """
    è®¡ç®— OCR ä»»åŠ¡çš„å¥–åŠ±åˆ†æ•°

    Args:
        pred: æ¨¡å‹é¢„æµ‹ç»“æœ
        gt: çœŸå®æ ‡ç­¾
        tag: æ•°æ®ç±»å‹ (text/table/formula)
        tool_call_count: å·¥å…·è°ƒç”¨æ¬¡æ•°
        tool_penalty: æ¯æ¬¡å·¥å…·è°ƒç”¨çš„æƒ©ç½š

    Returns:
        float: å¥–åŠ±åˆ†æ•°
    """
    # æ ¹æ®ç±»å‹è®¡ç®—åŸºç¡€åˆ†æ•°
    if tag == "text":
        base_score = compute_edit_distance_similarity(pred, gt)
    elif tag == "table":
        teds_result = compute_teds_score(pred, gt)
        base_score = teds_result.get("teds", 0.0)
    elif tag == "formula":
        formula_result = compute_formula_similarity(pred, gt)
        base_score = formula_result.get("f1_score", 0.0)
    else:
        base_score = compute_edit_distance_similarity(pred, gt)

    # æ‰£é™¤å·¥å…·è°ƒç”¨æƒ©ç½šï¼ˆé¼“åŠ±é«˜æ•ˆä½¿ç”¨å·¥å…·ï¼‰
    penalty = tool_call_count * tool_penalty
    final_score = max(0.0, base_score - penalty)

    return final_score
```

#### Phase 4: è®­ç»ƒé…ç½® (`examples/sglang_multiturn/config/ocr_resize_grpo.yaml`)

```yaml
# OCR Resize Agent GRPO è®­ç»ƒé…ç½®

hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

# æ•°æ®é…ç½®
data:
  train_path: ~/data/ocr_verl/train.parquet
  val_path: ~/data/ocr_verl/test.parquet
  max_prompt_length: 2048  # VLM éœ€è¦æ›´é•¿çš„ prompt
  max_response_length: 1024
  train_batch_size: 128
  return_raw_chat: True  # å¯ç”¨ raw chat æ ¼å¼

# Actor-Rollout-Ref é…ç½®
actor_rollout_ref:
  hybrid_engine: True
  model:
    path: Qwen/Qwen2.5-VL-3B-Instruct  # æˆ–å…¶ä»– VLM
  rollout:
    name: sglang
    mode: async
    prompt_length: ${data.max_prompt_length}
    response_length: ${data.max_response_length}
    # å¤šè½®é…ç½®
    multi_turn:
      enable: True
      max_assistant_turns: 5  # æœ€å¤š 5 è½® LLM ç”Ÿæˆ
      max_user_turns: 5       # æœ€å¤š 5 è½®ç”¨æˆ·/å·¥å…·å“åº”
      max_parallel_calls: 1   # æ¯è½®æœ€å¤š 1 ä¸ªå·¥å…·è°ƒç”¨
      max_tool_response_length: 512
      tool_response_truncate_side: middle
      tool_config_path: examples/sglang_multiturn/config/tool_config/ocr_resize_tool_config.yaml
      format: hermes  # å·¥å…·è°ƒç”¨æ ¼å¼
    # Trace é…ç½®ï¼ˆè°ƒè¯•ç”¨ï¼‰
    trace:
      backend: mlflow
      log_frequency: 100

# å¥–åŠ±æ¨¡å‹é…ç½®
reward_model:
  enable: True
  style: rule
  # è§„åˆ™å¥–åŠ±å‡½æ•°é…ç½®
  rule_reward:
    module: verl.utils.reward_score.ocr
    function: compute_score
    tool_penalty: 0.01  # æ¯æ¬¡å·¥å…·è°ƒç”¨æ‰£ 0.01

# è®­ç»ƒé…ç½®
algorithm:
  name: grpo  # ä½¿ç”¨ GRPO ç®—æ³•
  kl_ctrl:
    type: fixed
    kl_coef: 0.01

trainer:
  project_name: ocr_resize_agent
  experiment_name: grpo_qwen2.5vl_3b
  total_epochs: 3
  save_freq: 500
  logger:
    - tensorboard
    - mlflow
```

#### Phase 5: è®­ç»ƒå¯åŠ¨è„šæœ¬ (`examples/sglang_multiturn/run_ocr_resize_agent.sh`)

```bash
#!/bin/bash
# OCR Resize Agent è®­ç»ƒè„šæœ¬

set -e

# ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export VERL_LOGGING_LEVEL=INFO

# é…ç½®è·¯å¾„
CONFIG_NAME="ocr_resize_grpo"
DATA_DIR="${DATA_DIR:-~/data/ocr_verl}"
MODEL_PATH="${MODEL_PATH:-Qwen/Qwen2.5-VL-3B-Instruct}"
OUTPUT_DIR="${OUTPUT_DIR:-./outputs/ocr_resize_agent}"

# å¯åŠ¨è®­ç»ƒ
python3 -m verl.trainer.main_ppo \
    --config-name="${CONFIG_NAME}" \
    data.train_path="${DATA_DIR}/train.parquet" \
    data.val_path="${DATA_DIR}/test.parquet" \
    actor_rollout_ref.model.path="${MODEL_PATH}" \
    trainer.default_local_dir="${OUTPUT_DIR}" \
    trainer.project_name=ocr_resize_agent \
    "$@"
```

### 10.4 å®ç°è¿›åº¦ Checklist

| é˜¶æ®µ | ä»»åŠ¡ | çŠ¶æ€ | æ–‡ä»¶ä½ç½® |
|-----|------|------|---------|
| **Phase 1** | å®ç° `ImageResizeTool` | âœ… å·²å®Œæˆ | `verl/tools/image_resize_tool.py` |
| | å·¥å…·é…ç½® YAML | âœ… å·²å®Œæˆ | `examples/sglang_multiturn/config/tool_config/ocr_resize_tool_config.yaml` |
| **Phase 2** | æ•°æ®é¢„å¤„ç†è„šæœ¬ | âœ… å·²å®Œæˆ | `examples/data_preprocess/ocr_resize_agent_loop.py` |
| | ç”Ÿæˆè®­ç»ƒæ•°æ® | ğŸ”² å¾…è¿è¡Œ | `~/data/ocr_verl/` |
| **Phase 3** | OCR å¥–åŠ±å‡½æ•° | âœ… å·²å®Œæˆ | `verl/utils/reward_score/ocr.py` |
| | é›†æˆ TEDS/CDM | âš ï¸ éƒ¨åˆ†å®Œæˆ | éœ€å®‰è£… `table_recognition_metric` |
| **Phase 4** | GRPO è®­ç»ƒé…ç½® | âœ… å·²å®Œæˆ | `examples/sglang_multiturn/config/ocr_resize_grpo.yaml` |
| **Phase 5** | è®­ç»ƒå¯åŠ¨è„šæœ¬ | âœ… å·²å®Œæˆ | `examples/sglang_multiturn/run_ocr_resize_agent.sh` |
| | å•å…ƒæµ‹è¯• | ğŸ”² å¾…ç¼–å†™ | `tests/tools/test_image_resize_tool.py` |
| **Phase 6** | è®­ç»ƒéªŒè¯ | ğŸ”² å¾…è¿è¡Œ | - |
| | è¯„ä¼°å¯¹æ¯” | ğŸ”² å¾…è¿è¡Œ | ä½¿ç”¨ `eval_ocr/eval_ocr.py` |

### 10.4.1 å·²å®ç°æ–‡ä»¶æ¸…å•

ä»¥ä¸‹æ–‡ä»¶å·²åˆ›å»ºå®Œæˆï¼š

```
verl/
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ image_resize_tool.py        # ImageResizeTool å®ç°
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ reward_score/
â”‚       â””â”€â”€ ocr.py                  # OCR å¥–åŠ±å‡½æ•°
â””â”€â”€ examples/
    â”œâ”€â”€ data_preprocess/
    â”‚   â””â”€â”€ ocr_resize_agent_loop.py  # æ•°æ®é¢„å¤„ç†è„šæœ¬
    â””â”€â”€ sglang_multiturn/
        â”œâ”€â”€ config/
        â”‚   â”œâ”€â”€ ocr_resize_grpo.yaml  # GRPO è®­ç»ƒé…ç½®
        â”‚   â””â”€â”€ tool_config/
        â”‚       â””â”€â”€ ocr_resize_tool_config.yaml  # å·¥å…·é…ç½®
        â””â”€â”€ run_ocr_resize_agent.sh   # è®­ç»ƒå¯åŠ¨è„šæœ¬
```

### 10.5 ä¸ SFT è®­ç»ƒæ•°æ®çš„å¯¹é½éªŒè¯ï¼ˆè®­æ¨ä¸€è‡´æ€§ï¼‰

ä¸ºç¡®ä¿ RL è®­ç»ƒä¸ SFT è®­ç»ƒæ•°æ®çš„æ ¼å¼å®Œå…¨ä¸€è‡´ï¼Œå·²å®Œæˆä»¥ä¸‹å¯¹é½å·¥ä½œï¼š

#### 10.5.1 æ ¼å¼ä¸€è‡´æ€§å¯¹æ¯”è¡¨

| ç‰¹æ€§ | SFT æ•°æ®æ ¼å¼ | RL è®­ç»ƒæ ¼å¼ | çŠ¶æ€ |
|------|-------------|------------|------|
| **System Prompt** | æŒ‰ tag åˆ†ç±»ï¼ˆtext/table/equationï¼‰ | æŒ‰ tag åˆ†ç±» | âœ… ä¸€è‡´ |
| **User Prompt** | `<image>Extract...` | `<image>Extract...` | âœ… ä¸€è‡´ |
| **å·¥å…·è°ƒç”¨æ ¼å¼** | `<tool_call>...</tool_call>` | `<tool_call>...</tool_call>` | âœ… ä¸€è‡´ |
| **å…è®¸çš„ scale å€¼** | `[0.125, 0.143, 0.167, 0.2, 0.25, 0.333, 0.5, 2, 3, 4, 5, 6, 7, 8]` | ç›¸åŒ | âœ… ä¸€è‡´ |
| **å·¥å…·å“åº”æ ¼å¼** | `Resize complete. New scale: {scale}x\nResult:<image>` | ç›¸åŒ | âœ… ä¸€è‡´ |
| **è¾“å‡ºæ ¼å¼** | `<final_answer>...</final_answer>` | åœ¨ prompt ä¸­è¯´æ˜ | âœ… ä¸€è‡´ |

#### 10.5.2 SFT æ•°æ®ç¤ºä¾‹

```json
{
  "data_id": "equation_isolated_000587",
  "tag": "equation",
  "messages": [
    {
      "role": "system",
      "content": "You are an expert OCR assistant. Your task is to accurately extract the mathematical equation from the given image and output it in LaTeX format.\n\nYou have access to a resize tool that can adjust the image resolution:\n<tool_call>{\"name\": \"resize\", \"arguments\": {\"scale\": N}}</tool_call>\nwhere N can be: 0.125, 0.143, 0.167, 0.2, 0.25, 0.333, 0.5, 2, 3, 4, 5, 6, 7, 8\n..."
    },
    {
      "role": "user",
      "content": "<image>Extract the mathematical equation from this image in LaTeX format."
    },
    {
      "role": "assistant",
      "content": "Analyzing the image, I think downscaling would improve equation recognition accuracy.\n<tool_call>{\"name\": \"resize\", \"arguments\": {\"scale\": 0.25}}</tool_call>"
    },
    {
      "role": "user",
      "content": "Resize complete. New scale: 0.25x\nResult:<image>"
    },
    {
      "role": "assistant",
      "content": "<final_answer>$$F_n = 2^{2^n} + 1.$$</final_answer>"
    }
  ],
  "images": [
    {"image": "/path/to/original.jpg"},
    {"image": "/path/to/resized.jpg"}
  ]
}
```

#### 10.5.3 å…³é”®å¯¹é½ç‚¹

1. **System Prompt æŒ‰ tag åˆ†ç±»**ï¼š
   - `text`: æå–æ–‡æœ¬å†…å®¹
   - `table`: æå–è¡¨æ ¼å¹¶è¾“å‡º HTML æ ¼å¼
   - `equation`: æå–å…¬å¼å¹¶è¾“å‡º LaTeX æ ¼å¼

2. **å·¥å…·å“åº”æ ¼å¼**ï¼š
   ```
   Resize complete. New scale: {scale}x
   Result:<image>
   ```

3. **è¾“å‡ºæ ¼å¼è¦æ±‚**ï¼š
   - æœ€ç»ˆç»“æœéœ€ç”¨ `<final_answer>` æ ‡ç­¾åŒ…è£¹

**éªŒè¯è„šæœ¬**ï¼š

```python
# tests/tools/test_ocr_consistency.py
"""éªŒè¯è®­ç»ƒä¸ SFT æ•°æ®çš„ä¸€è‡´æ€§"""

def test_message_format_consistency():
    """éªŒè¯æ¶ˆæ¯æ ¼å¼ä¸€è‡´æ€§"""
    from verl.examples.data_preprocess.ocr_resize_agent_loop import SYSTEM_PROMPTS, USER_PROMPTS

    # éªŒè¯ equation ç±»å‹çš„ prompt
    assert "LaTeX format" in SYSTEM_PROMPTS["equation"]
    assert "<tool_call>" in SYSTEM_PROMPTS["equation"]
    assert "<final_answer>" in SYSTEM_PROMPTS["equation"]
    assert USER_PROMPTS["equation"] == "Extract the mathematical equation from this image in LaTeX format."

def test_tool_call_parsing_consistency():
    """éªŒè¯å·¥å…·è°ƒç”¨è§£æä¸€è‡´æ€§"""
    from eval_ocr.eval_ocr import parse_tool_call

    test_cases = [
        ('<tool_call>{"name": "resize", "arguments": {"scale": 2.0}}</tool_call>',
         {"name": "resize", "arguments": {"scale": 2.0}}),
        ('<tool_call>{"name": "resize", "arguments": {"scale": 0.125}}</tool_call>',
         {"name": "resize", "arguments": {"scale": 0.125}}),
        ('No tool call here', None),
    ]

    for text, expected in test_cases:
        result = parse_tool_call(text)
        assert result == expected, f"Mismatch for: {text}"

def test_tool_response_format():
    """éªŒè¯å·¥å…·å“åº”æ ¼å¼"""
    # SFT æ•°æ®ä¸­çš„å·¥å…·å“åº”æ ¼å¼
    sft_response = "Resize complete. New scale: 0.25x\nResult:<image>"

    # å·¥å…·å®ç°ä¸­çš„å“åº”æ ¼å¼
    scale = 0.25
    tool_response = f"Resize complete. New scale: {scale}x\nResult:"

    # éªŒè¯æ ¼å¼ä¸€è‡´ï¼ˆé™¤äº† <image> å ä½ç¬¦ç”±æ¡†æ¶å¤„ç†ï¼‰
    assert tool_response in sft_response.replace("<image>", "")
```

### 10.6 è®­ç»ƒç›‘æ§ä¸è°ƒè¯•

#### MLflow Trace æŸ¥çœ‹

```bash
# å¯åŠ¨ MLflow UI
mlflow ui --port 5000

# åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://localhost:5000
# æŸ¥çœ‹ï¼š
# - agent_loop/tool_calls: å·¥å…·è°ƒç”¨æ¬¡æ•°
# - reward_value: å¥–åŠ±åˆ†å¸ƒ
# - response_length: å“åº”é•¿åº¦åˆ†å¸ƒ
```

#### å¸¸è§é—®é¢˜æ’æŸ¥

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|-----|---------|---------|
| å·¥å…·ä»ä¸è¢«è°ƒç”¨ | System prompt ä¸å¤Ÿæ˜ç¡® | è°ƒæ•´ promptï¼Œå¢åŠ å·¥å…·ä½¿ç”¨ç¤ºä¾‹ |
| å·¥å…·è¢«è¿‡åº¦è°ƒç”¨ | tool_penalty å¤ªå° | å¢å¤§ `tool_penalty` å‚æ•° |
| å¥–åŠ±ä¸æ”¶æ•› | å¥–åŠ±å‡½æ•°è®¾è®¡é—®é¢˜ | æ£€æŸ¥å¥–åŠ±è®¡ç®—é€»è¾‘ï¼Œè°ƒæ•´æƒé‡ |
| OOM | å›¾åƒå¤ªå¤§ | é™åˆ¶ `max_prompt_length`ï¼Œé™ä½ batch size |
| Tokenization ä¸ä¸€è‡´ | Processor é…ç½®é—®é¢˜ | ç¡®ä¿è®­ç»ƒå’Œè¯„ä¼°ä½¿ç”¨ç›¸åŒçš„ processor |
